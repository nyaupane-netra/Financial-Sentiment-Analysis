{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Financial BERT Training (Local Jupyter Version)\n",
    "This notebook includes full environment setup for local Jupyter Notebook (Python 3.12, Anaconda, VS Code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.36.2\n",
      "Uninstalling transformers-4.36.2:\n",
      "  Successfully uninstalled transformers-4.36.2\n",
      "Found existing installation: accelerate 1.11.0\n",
      "Uninstalling accelerate-1.11.0:\n",
      "  Successfully uninstalled accelerate-1.11.0\n",
      "Found existing installation: tensorflow 2.17.0\n",
      "Uninstalling tensorflow-2.17.0:\n",
      "  Successfully uninstalled tensorflow-2.17.0\n",
      "Found existing installation: keras 3.6.0\n",
      "Uninstalling keras-3.6.0:\n",
      "  Successfully uninstalled keras-3.6.0\n",
      "\u001b[33mWARNING: Skipping tf-keras as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mEnvironment setup complete. Please restart the Jupyter kernel.\n"
     ]
    }
   ],
   "source": [
    "# ==== ENVIRONMENT SETUP ====\n",
    "!pip uninstall -y transformers accelerate tensorflow keras tf-keras\n",
    "!pip install \"transformers==4.36.2\" \"accelerate==0.24.1\" --quiet\n",
    "!pip install datasets evaluate scikit-learn pandas numpy --quiet\n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_TF_WARNING\"] = \"1\"\n",
    "\n",
    "print(\"Environment setup complete. Please restart the Jupyter kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Kaggle Dataset (Local File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...      2\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...      2\n",
       "2  user I'd be afraid to short AMZN - they are lo...      2\n",
       "3                                  MNTA Over 12.00        2\n",
       "4                                   OI  Over 21.37        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace with your actual filename in the notebook folder\n",
    "kaggle_file = \"stock_data.csv\"\n",
    "df_kaggle = pd.read_csv(kaggle_file)\n",
    "\n",
    "label_map = {-1:0, 0:1, 1:2}\n",
    "df_kaggle[\"label\"] = df_kaggle[\"Sentiment\"].map(label_map)\n",
    "df_kaggle = df_kaggle[[\"Text\", \"label\"]]\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PhraseBank Dataset (Local File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label\n",
       "0  According to Gran , the company has no plans t...      1\n",
       "1  Technopolis plans to develop in stages an area...      1\n",
       "2  The international electronic industry company ...      0\n",
       "3  With the new production plant the company woul...      2\n",
       "4  According to the company 's updated strategy f...      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasebank_file = \"Sentences_50Agree.txt\"  # update if needed\n",
    "texts=[]; labels=[]\n",
    "\n",
    "with open(phrasebank_file, 'r', encoding='ISO-8859-1', errors='replace') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if '@positive' in line:\n",
    "            texts.append(line.replace('@positive','').strip()); labels.append(2)\n",
    "        elif '@neutral' in line:\n",
    "            texts.append(line.replace('@neutral','').strip()); labels.append(1)\n",
    "        elif '@negative' in line:\n",
    "            texts.append(line.replace('@negative','').strip()); labels.append(0)\n",
    "\n",
    "df_phrase = pd.DataFrame({'Text':texts, 'label':labels})\n",
    "df_phrase.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Datasets & Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32155623ff2b427eb9b2653567aaf65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8509 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672b2081083e44aaaa250486a70a6b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Merge\n",
    "import pandas as pd\n",
    "df = pd.concat([df_phrase, df_kaggle], ignore_index=True)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenization\n",
    "from transformers import BertTokenizerFast\n",
    "SEQ_LEN = 256\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tok(batch):\n",
    "    return tokenizer(batch['Text'], truncation=True, padding='max_length', max_length=SEQ_LEN)\n",
    "\n",
    "enc = DatasetDict({\n",
    "    'train': train_ds.map(tok, batched=True).remove_columns(['Text']).rename_column('label','labels'),\n",
    "    'test': test_ds.map(tok, batched=True).remove_columns(['Text']).rename_column('label','labels')\n",
    "})\n",
    "\n",
    "enc.set_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "W1119 22:51:03.710000 91553 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1596' max='1596' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1596/1596 52:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.431853</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.814792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.409530</td>\n",
       "      <td>0.835996</td>\n",
       "      <td>0.834869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.619554</td>\n",
       "      <td>0.836466</td>\n",
       "      <td>0.836191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1596, training_loss=0.32748962315102864, metrics={'train_runtime': 3172.5129, 'train_samples_per_second': 8.046, 'train_steps_per_second': 0.503, 'total_flos': 3358248107171328.0, 'train_loss': 0.32748962315102864, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "acc = evaluate.load('accuracy'); f1 = evaluate.load('f1')\n",
    "\n",
    "def metrics(p):\n",
    "    logits, labels = p\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        'accuracy': acc.compute(predictions=preds, references=labels)['accuracy'],\n",
    "        'f1_weighted': f1.compute(predictions=preds, references=labels, average='weighted')['f1']\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./custom_finbert',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=enc['train'],\n",
    "    eval_dataset=enc['test'],\n",
    "    compute_metrics=metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "trainer.save_model(\"custom_financial_bert\")\n",
    "tokenizer.save_pretrained(\"custom_financial_bert\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def predict_batch(text_list):\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # Ensure model and tensors are on CPU\n",
    "    model_cpu = model.to(\"cpu\")\n",
    "    inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_cpu(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "    id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "    # FIXED — added the missing closing bracket\n",
    "    return [id2label[p] for p in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT: The value of the deal exceeds EUR500 ,000 , the company said .\n",
      "TRUE LABEL: neutral\n",
      "MODEL PRED: neutral\n",
      "\n",
      "TEXT: Trading in the new shares , which have right to dividends and other distributions of funds , will start on the exchange in Helsinki tomorrow .\n",
      "TRUE LABEL: neutral\n",
      "MODEL PRED: neutral\n",
      "\n",
      "TEXT: The deal covers Stockmann Auto Oy Ab 's sales and after-sales services concerning Volkswagen and Audi in Helsinki , Espoo and Vantaa .\n",
      "TRUE LABEL: neutral\n",
      "MODEL PRED: neutral\n",
      "\n",
      "TEXT: And when it has lifted the veil on the various types of customer for which it designs its phones , the result is social stereotyping taken to a fine art .\n",
      "TRUE LABEL: neutral\n",
      "MODEL PRED: neutral\n",
      "\n",
      "TEXT: The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 .\n",
      "TRUE LABEL: neutral\n",
      "MODEL PRED: neutral\n",
      "\n",
      "TEXT: One small step to send cable TV back to the 80s. Quality content exclusive on NFX. Can't wait for the return of AD.  \n",
      "TRUE LABEL: positive\n",
      "MODEL PRED: negative\n",
      "\n",
      "TEXT: the last two times I saw Warren Buffett he told me to 'Catch p' ....i just thought I was slow! .... ahhhhh hnz\n",
      "TRUE LABEL: positive\n",
      "MODEL PRED: positive\n",
      "\n",
      "TEXT: `` The CHF is a great product .\n",
      "TRUE LABEL: positive\n",
      "MODEL PRED: positive\n",
      "\n",
      "TEXT: Some math HHC sold 206 condo units in 29 hours in Hawaii in Dec. Avg 1100 sqft, avg 1,500 sqft/condo (1.65M /unit) (own 25% of project)\n",
      "TRUE LABEL: positive\n",
      "MODEL PRED: positive\n",
      "\n",
      "TEXT: The intent of the article was to focus attention on the fact that the development model that China had followed was very different than the model that India had followed .\n",
      "TRUE LABEL: neutral\n",
      "MODEL PRED: neutral\n"
     ]
    }
   ],
   "source": [
    "sample_texts = test_df[\"Text\"].iloc[:10].tolist()\n",
    "sample_labels = test_df[\"label\"].iloc[:10].tolist()\n",
    "\n",
    "preds = predict_batch(sample_texts)\n",
    "\n",
    "for text, true_label, pred in zip(sample_texts, sample_labels, preds):\n",
    "    print(\"\\nTEXT:\", text)\n",
    "    print(\"TRUE LABEL:\", {0:\"negative\",1:\"neutral\",2:\"positive\"}[true_label])\n",
    "    print(\"MODEL PRED:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    model_cpu = model.to(\"cpu\")\n",
    "    inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_cpu(**inputs)\n",
    "\n",
    "    pred = torch.argmax(outputs.logits).item()\n",
    "    return {0:\"negative\",1:\"neutral\",2:\"positive\"}[pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Apple has done good sales this week.\"\n",
    "print(\"Prediction:\", predict_single(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: negative\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Company lost its half of the customer\"\n",
    "print(\"Prediction:\", predict_single(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: neutral\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  Operating profit totalled EUR 21.1 mn , up from EUR 18.6 mn in 2007 , representing 9.7 % of net sales .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  Investor confidence increased as the stock surged in after-hours trading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  The company is facing a lawsuit that could impact its financial outlook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  I am very happy today\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  The company released its annual financial report on Wednesday.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: neutral\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text (type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "def sentiment():\n",
    "    while True:\n",
    "        text = input(\"\\nEnter text (type 'exit' to quit): \")\n",
    "        if text.lower() == \"exit\":\n",
    "            break\n",
    "        print(\"Prediction:\", predict_single(text))\n",
    "\n",
    "# Run interactive tester\n",
    "sentiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0.0009611451532691717, 'neutral': 0.001899946597404778, 'positive': 0.9971389770507812}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_with_probs(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = F.softmax(logits, dim=1).numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"negative\": float(probs[0]),\n",
    "        \"neutral\": float(probs[1]),\n",
    "        \"positive\": float(probs[2])\n",
    "    }\n",
    "\n",
    "print(predict_with_probs(\"The economy is showing strong signs of recovery.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "def predict_with_probs(text):\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # Ensure CPU execution\n",
    "    inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "    model_cpu = model.to(\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(**inputs).logits\n",
    "\n",
    "    # Softmax → probabilities (convert to numpy)\n",
    "    probs = F.softmax(logits, dim=1).numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"negative\": float(probs[0]),\n",
    "        \"neutral\": float(probs[1]),\n",
    "        \"positive\": float(probs[2]),\n",
    "        \"predicted_label\": id2label[int(probs.argmax())]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text:  For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities:\n",
      "  Negative: 0.0007\n",
      "  Neutral:  0.0008\n",
      "  Positive: 0.9986\n",
      "Prediction: positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text:  I am Nabin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities:\n",
      "  Negative: 0.1119\n",
      "  Neutral:  0.0012\n",
      "  Positive: 0.8870\n",
      "Prediction: positive\n"
     ]
    }
   ],
   "source": [
    "def sentiment_loop():\n",
    "    print(\"Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        text = input(\"\\nEnter text: \")\n",
    "        if text.lower() == \"exit\":\n",
    "            break\n",
    "        result = predict_with_probs(text)\n",
    "        print(\"\\nProbabilities:\")\n",
    "        print(f\"  Negative: {result['negative']:.4f}\")\n",
    "        print(f\"  Neutral:  {result['neutral']:.4f}\")\n",
    "        print(f\"  Positive: {result['positive']:.4f}\")\n",
    "        print(\"Prediction:\", result[\"predicted_label\"])\n",
    "\n",
    "# Run it\n",
    "sentiment_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"custom_financial_bert\", safe_serialization=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
